#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨ç†æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¸åŒé…ç½®ä¸‹çš„æ¨ç†æ€§èƒ½å’ŒCPUåˆ©ç”¨ç‡
"""

import os
import sys
import time
import psutil
import threading
import subprocess
from datetime import datetime
import numpy as np

def monitor_system_performance(duration=30, interval=1):
    """ç›‘æ§ç³»ç»Ÿæ€§èƒ½"""
    print(f"å¼€å§‹ç›‘æ§ç³»ç»Ÿæ€§èƒ½ï¼ŒæŒç»­ {duration} ç§’...")
    
    cpu_data = []
    memory_data = []
    process_data = []
    
    start_time = time.time()
    
    while time.time() - start_time < duration:
        timestamp = time.time() - start_time
        
        # CPUä½¿ç”¨æƒ…å†µ
        cpu_percent = psutil.cpu_percent(interval=None, percpu=True)
        active_cores = sum(1 for usage in cpu_percent if usage > 5.0)
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        
        # Pythonè¿›ç¨‹ä¿¡æ¯
        python_processes = []
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent', 'num_threads']):
            try:
                if 'python' in proc.info['name'].lower():
                    python_processes.append({
                        'pid': proc.info['pid'],
                        'cpu_percent': proc.info['cpu_percent'],
                        'memory_percent': proc.info['memory_percent'],
                        'num_threads': proc.info['num_threads']
                    })
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
        
        # è®°å½•æ•°æ®
        cpu_data.append({
            'time': timestamp,
            'overall_cpu': sum(cpu_percent) / len(cpu_percent),
            'max_cpu': max(cpu_percent),
            'active_cores': active_cores,
            'total_cores': len(cpu_percent)
        })
        
        memory_data.append({
            'time': timestamp,
            'percent': memory.percent,
            'available_gb': memory.available / (1024**3),
            'used_gb': memory.used / (1024**3)
        })
        
        process_data.append({
            'time': timestamp,
            'python_processes': len(python_processes),
            'total_cpu_by_python': sum(p['cpu_percent'] for p in python_processes),
            'total_memory_by_python': sum(p['memory_percent'] for p in python_processes)
        })
        
        # å®æ—¶æ˜¾ç¤º
        print(f"\ræ—¶é—´: {timestamp:6.1f}s | "
              f"æ´»è·ƒæ ¸å¿ƒ: {active_cores:2d}/{len(cpu_percent)} | "
              f"å¹³å‡CPU: {sum(cpu_percent)/len(cpu_percent):5.1f}% | "
              f"æœ€å¤§CPU: {max(cpu_percent):5.1f}% | "
              f"å†…å­˜: {memory.percent:5.1f}% | "
              f"Pythonè¿›ç¨‹: {len(python_processes)}", 
              end="", flush=True)
        
        time.sleep(interval)
    
    print("\nç›‘æ§å®Œæˆ")
    
    return {
        'cpu_data': cpu_data,
        'memory_data': memory_data,
        'process_data': process_data
    }

def analyze_performance_data(data):
    """åˆ†ææ€§èƒ½æ•°æ®"""
    cpu_data = data['cpu_data']
    memory_data = data['memory_data']
    process_data = data['process_data']
    
    if not cpu_data:
        print("æ²¡æœ‰æ€§èƒ½æ•°æ®å¯åˆ†æ")
        return
    
    # CPUåˆ†æ
    avg_cpu = np.mean([d['overall_cpu'] for d in cpu_data])
    max_cpu = np.max([d['max_cpu'] for d in cpu_data])
    avg_active_cores = np.mean([d['active_cores'] for d in cpu_data])
    max_active_cores = np.max([d['active_cores'] for d in cpu_data])
    total_cores = cpu_data[0]['total_cores']
    
    # å†…å­˜åˆ†æ
    avg_memory = np.mean([d['percent'] for d in memory_data])
    max_memory = np.max([d['percent'] for d in memory_data])
    
    # è¿›ç¨‹åˆ†æ
    avg_python_processes = np.mean([d['python_processes'] for d in process_data])
    max_python_processes = np.max([d['python_processes'] for d in process_data])
    avg_python_cpu = np.mean([d['total_cpu_by_python'] for d in process_data])
    
    print("\n=== æ€§èƒ½åˆ†æç»“æœ ===")
    print(f"CPUä½¿ç”¨æƒ…å†µ:")
    print(f"  å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%")
    print(f"  æœ€å¤§CPUä½¿ç”¨ç‡: {max_cpu:.1f}%")
    print(f"  å¹³å‡æ´»è·ƒæ ¸å¿ƒ: {avg_active_cores:.1f}/{total_cores}")
    print(f"  æœ€å¤§æ´»è·ƒæ ¸å¿ƒ: {max_active_cores}/{total_cores}")
    print(f"  æ ¸å¿ƒåˆ©ç”¨ç‡: {(avg_active_cores/total_cores)*100:.1f}%")
    
    print(f"\nå†…å­˜ä½¿ç”¨æƒ…å†µ:")
    print(f"  å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {avg_memory:.1f}%")
    print(f"  æœ€å¤§å†…å­˜ä½¿ç”¨ç‡: {max_memory:.1f}%")
    
    print(f"\nè¿›ç¨‹æƒ…å†µ:")
    print(f"  å¹³å‡Pythonè¿›ç¨‹æ•°: {avg_python_processes:.1f}")
    print(f"  æœ€å¤§Pythonè¿›ç¨‹æ•°: {max_python_processes}")
    print(f"  Pythonè¿›ç¨‹å¹³å‡CPUä½¿ç”¨: {avg_python_cpu:.1f}%")
    
    # è¯Šæ–­å»ºè®®
    print(f"\n=== è¯Šæ–­å»ºè®® ===")
    if avg_active_cores < total_cores * 0.3:
        print("âš ï¸  CPUæ ¸å¿ƒåˆ©ç”¨ç‡è¾ƒä½ï¼Œå¯èƒ½å­˜åœ¨ä»¥ä¸‹é—®é¢˜:")
        print("   - I/Oç“¶é¢ˆï¼šæ•°æ®åŠ è½½é€Ÿåº¦é™åˆ¶äº†CPUä½¿ç”¨")
        print("   - è¿›ç¨‹é—´ç«äº‰ï¼šè¿‡å¤šå·¥ä½œè¿›ç¨‹å¯¼è‡´èµ„æºç«äº‰")
        print("   - GILé™åˆ¶ï¼šæŸäº›æ“ä½œå—åˆ°Python GILé™åˆ¶")
        print("   å»ºè®®ï¼šå‡å°‘num_workersï¼Œå¢åŠ batch_size")
    elif avg_active_cores > total_cores * 0.8:
        print("âœ… CPUæ ¸å¿ƒåˆ©ç”¨ç‡è‰¯å¥½ï¼Œç³»ç»Ÿè´Ÿè½½å‡è¡¡")
    else:
        print("ğŸ“Š CPUæ ¸å¿ƒåˆ©ç”¨ç‡ä¸­ç­‰ï¼Œå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    if avg_memory > 80:
        print("âš ï¸  å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
        print("   å»ºè®®ï¼šå‡å°‘batch_sizeæˆ–num_workers")
    
    if max_python_processes > 20:
        print("âš ï¸  Pythonè¿›ç¨‹æ•°è¿‡å¤šï¼Œå¯èƒ½å¯¼è‡´èµ„æºç«äº‰")
        print("   å»ºè®®ï¼šå‡å°‘num_workers")

def test_inference_configurations():
    """æµ‹è¯•ä¸åŒçš„æ¨ç†é…ç½®"""
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„æ–‡ä»¶
    script_path = "./PatchTST_supervised/scripts/PatchTST/run_inference_for_web.sh"
    if not os.path.exists(script_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨ç†è„šæœ¬ {script_path}")
        return
    
    print("=== æ¨ç†æ€§èƒ½æµ‹è¯• ===")
    print(f"ç³»ç»Ÿä¿¡æ¯:")
    print(f"  CPUæ ¸å¿ƒæ•°: {psutil.cpu_count()} (é€»è¾‘)")
    print(f"  ç‰©ç†æ ¸å¿ƒæ•°: {psutil.cpu_count(logical=False)}")
    print(f"  æ€»å†…å­˜: {psutil.virtual_memory().total / (1024**3):.1f} GB")
    
    # æµ‹è¯•é…ç½®
    test_configs = [
        {"num_workers": 1, "batch_size": 512, "description": "å•è¿›ç¨‹åŸºå‡†æµ‹è¯•"},
        {"num_workers": 4, "batch_size": 512, "description": "4è¿›ç¨‹ä¸­ç­‰æ‰¹æ¬¡"},
        {"num_workers": 6, "batch_size": 1024, "description": "6è¿›ç¨‹å¤§æ‰¹æ¬¡ï¼ˆå½“å‰é…ç½®ï¼‰"},
        {"num_workers": 8, "batch_size": 512, "description": "8è¿›ç¨‹ä¸­ç­‰æ‰¹æ¬¡"},
        {"num_workers": 12, "batch_size": 512, "description": "12è¿›ç¨‹ä¸­ç­‰æ‰¹æ¬¡"},
    ]
    
    results = []
    
    for i, config in enumerate(test_configs):
        print(f"\n--- æµ‹è¯•é…ç½® {i+1}/{len(test_configs)}: {config['description']} ---")
        print(f"num_workers: {config['num_workers']}, batch_size: {config['batch_size']}")
        
        # ä¿®æ”¹é…ç½®æ–‡ä»¶
        modify_config_file(script_path, config['num_workers'], config['batch_size'])
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        monitor_duration = 45  # ç»™æ¨ç†è¶³å¤Ÿçš„æ—¶é—´
        performance_data = None
        
        def run_monitoring():
            nonlocal performance_data
            performance_data = monitor_system_performance(monitor_duration, 1)
        
        monitor_thread = threading.Thread(target=run_monitoring, daemon=True)
        monitor_thread.start()
        
        # ç­‰å¾…ç›‘æ§å¯åŠ¨
        time.sleep(2)
        
        # è¿è¡Œæ¨ç†ï¼ˆé™åˆ¶æ—¶é—´ï¼‰
        try:
            print("å¼€å§‹æ¨ç†...")
            process = subprocess.Popen(
                [script_path], 
                stdout=subprocess.PIPE, 
                stderr=subprocess.STDOUT, 
                text=True,
                timeout=40  # 40ç§’è¶…æ—¶
            )
            
            # è¯»å–è¾“å‡ºä½†ä¸é˜»å¡
            output_lines = []
            while process.poll() is None:
                line = process.stdout.readline()
                if line:
                    output_lines.append(line.strip())
                    if len(output_lines) <= 5:  # åªæ˜¾ç¤ºå‰å‡ è¡Œ
                        print(f"[æ¨ç†] {line.strip()}")
            
            return_code = process.returncode
            
        except subprocess.TimeoutExpired:
            print("æ¨ç†è¶…æ—¶ï¼Œç»ˆæ­¢è¿›ç¨‹")
            process.kill()
            return_code = -1
        except Exception as e:
            print(f"æ¨ç†æ‰§è¡Œé”™è¯¯: {e}")
            return_code = -1
        
        # ç­‰å¾…ç›‘æ§å®Œæˆ
        monitor_thread.join(timeout=5)
        
        if performance_data:
            print(f"\næ¨ç†å®Œæˆï¼Œè¿”å›ç : {return_code}")
            analyze_performance_data(performance_data)
            results.append({
                'config': config,
                'performance_data': performance_data,
                'return_code': return_code
            })
        
        print("\n" + "="*60)
        time.sleep(3)  # è®©ç³»ç»Ÿä¼‘æ¯ä¸€ä¸‹
    
    # è¾“å‡ºæœ€ç»ˆå»ºè®®
    print("\n=== æœ€ç»ˆå»ºè®® ===")
    print("åŸºäºæµ‹è¯•ç»“æœï¼Œå»ºè®®é€‰æ‹©CPUæ ¸å¿ƒåˆ©ç”¨ç‡æœ€é«˜ä¸”å†…å­˜ä½¿ç”¨åˆç†çš„é…ç½®")

def modify_config_file(script_path, num_workers, batch_size):
    """ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°"""
    try:
        with open(script_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ›¿æ¢NUM_WORKERSå’ŒBATCH_SIZE
        import re
        content = re.sub(r'NUM_WORKERS=\d+', f'NUM_WORKERS={num_workers}', content)
        content = re.sub(r'BATCH_SIZE=\d+', f'BATCH_SIZE={batch_size}', content)
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"å·²æ›´æ–°é…ç½®: NUM_WORKERS={num_workers}, BATCH_SIZE={batch_size}")
        
    except Exception as e:
        print(f"ä¿®æ”¹é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1 and sys.argv[1] == "--monitor-only":
        # ä»…ç›‘æ§æ¨¡å¼
        print("ä»…ç›‘æ§æ¨¡å¼ï¼Œç›‘æ§60ç§’...")
        data = monitor_system_performance(60, 1)
        analyze_performance_data(data)
    else:
        # å®Œæ•´æµ‹è¯•æ¨¡å¼
        test_inference_configurations()

if __name__ == "__main__":
    main()
